mysql> select * from Emp_team;
+---------+-------------------+--------+
| Team_id | Team_name         | Emp_id |
+---------+-------------------+--------+
|       1 | Manchester United |      1 |
|       2 | Team India        |      1 |
|       2 | Team India        |      2 |
|       3 | Barcelona         |      3 |
|       4 | Switzerland       |      4 |
|       5 | Real Madrid       |      5 |
|       6 | Argentina         |      3 |
|       7 | Portugal          |      5 |
|       8 | Spain             |      6 |
|       1 | Manchester United |      7 |
|       9 | Bayern Munich     |     11 |
|       2 | Team India        |     10 |
|       1 | Manchester United |      8 |
+---------+-------------------+--------+
13 rows in set (0.00 sec)

mysql> select * from Employee;
+--------+----------+------------+---------------------+
| Emp_id | Emp_Name | Emp_sal    | Row_ts              |
+--------+----------+------------+---------------------+
|      1 | Deepak   |   75000.00 | 2016-06-13 17:06:27 |
|      2 | Sachin   | 1500000.00 | 2016-06-13 17:07:51 |
|      3 | Messi    | 2500000.00 | 2016-06-13 17:08:04 |
|      4 | Federer  | 2000000.00 | 2016-06-13 17:48:19 |
|      5 | Ronaldo  | 2750000.00 | 2016-06-18 08:28:31 |
|      6 | Iniesta  | 1000000.00 | 2016-06-20 20:47:12 |
|      7 | Giggs    |  900000.00 | 2016-06-20 20:47:43 |
|      8 | Rooney   | 2000000.00 | 2016-06-20 20:48:40 |
|      9 | Neymar   | 1750000.00 | 2016-06-20 20:49:06 |
|     10 | Dhoni    | 2100000.00 | 2016-06-20 20:50:22 |
+--------+----------+------------+---------------------+
10 rows in set (0.00 sec)

mysql> select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id;
+--------+----------+-------------------+
| Emp_id | Emp_name | Team_name         |
+--------+----------+-------------------+
|      1 | Deepak   | Manchester United |
|      1 | Deepak   | Team India        |
|      2 | Sachin   | Team India        |
|      3 | Messi    | Barcelona         |
|      4 | Federer  | Switzerland       |
|      5 | Ronaldo  | Real Madrid       |
|      3 | Messi    | Argentina         |
|      5 | Ronaldo  | Portugal          |
|      6 | Iniesta  | Spain             |
|      7 | Giggs    | Manchester United |
|     10 | Dhoni    | Team India        |
|      8 | Rooney   | Manchester United |
+--------+----------+-------------------+
12 rows in set (0.00 sec)
====================================================================================================
[hduser@Inceptez ~]$ sqoop import --connect jdbc:mysql://localhost/DKMDB01 --username root -P --direct --table Emp_team --num-mappers 2 --target-dir sqoopdb;
Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/local/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
16/06/20 21:03:44 INFO sqoop.Sqoop: Running Sqoop version: 1.4.5
Enter password: 
16/06/20 21:03:47 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/06/20 21:03:47 INFO tool.CodeGenTool: Beginning code generation
16/06/20 21:03:48 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `Emp_team` AS t LIMIT 1
16/06/20 21:03:48 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `Emp_team` AS t LIMIT 1
16/06/20 21:03:48 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/local/hadoop
Note: /tmp/sqoop-hduser/compile/2658e6f06fba74a88ffc97b288f11f01/Emp_team.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/06/20 21:03:56 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hduser/compile/2658e6f06fba74a88ffc97b288f11f01/Emp_team.jar
16/06/20 21:03:56 ERROR tool.ImportTool: Error during import: No primary key could be found for table Emp_team. Please specify one with --split-by or perform a sequential import with '-m 1'.

[hduser@Inceptez ~]$ sqoop import --connect jdbc:mysql://localhost/DKMDB01 --username root -P --direct --table Employee --split-by Emp_id --num-mappers 2 --target-dir sqoopdb/Employee_new1;
Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/local/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
16/06/20 21:06:34 INFO sqoop.Sqoop: Running Sqoop version: 1.4.5
Enter password: 
16/06/20 21:06:39 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/06/20 21:06:39 INFO tool.CodeGenTool: Beginning code generation
16/06/20 21:06:40 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `Employee` AS t LIMIT 1
16/06/20 21:06:40 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `Employee` AS t LIMIT 1
16/06/20 21:06:40 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/local/hadoop
Note: /tmp/sqoop-hduser/compile/f553948103f63a63af829b2f86ee3fdf/Employee.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/06/20 21:06:45 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hduser/compile/f553948103f63a63af829b2f86ee3fdf/Employee.jar
16/06/20 21:06:46 INFO manager.DirectMySQLManager: Beginning mysqldump fast path import
16/06/20 21:06:46 INFO mapreduce.ImportJobBase: Beginning import of Employee
16/06/20 21:06:47 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/06/20 21:06:47 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
16/06/20 21:06:49 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
16/06/20 21:06:49 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/06/20 21:06:54 INFO db.DBInputFormat: Using read commited transaction isolation
16/06/20 21:06:54 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(`Emp_id`), MAX(`Emp_id`) FROM Employee
16/06/20 21:06:54 INFO mapreduce.JobSubmitter: number of splits:2
16/06/20 21:06:56 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1466435175955_0001
16/06/20 21:06:58 INFO impl.YarnClientImpl: Submitted application application_1466435175955_0001
16/06/20 21:06:58 INFO mapreduce.Job: The url to track the job: http://Inceptez:8088/proxy/application_1466435175955_0001/
16/06/20 21:06:58 INFO mapreduce.Job: Running job: job_1466435175955_0001
16/06/20 21:07:27 INFO mapreduce.Job: Job job_1466435175955_0001 running in uber mode : false
16/06/20 21:07:27 INFO mapreduce.Job:  map 0% reduce 0%
16/06/20 21:08:04 INFO mapreduce.Job:  map 100% reduce 0%
16/06/20 21:08:05 INFO mapreduce.Job: Job job_1466435175955_0001 completed successfully
16/06/20 21:08:06 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=229890
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=214
		HDFS: Number of bytes written=398
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Job Counters 
		Launched map tasks=2
		Other local map tasks=2
		Total time spent by all maps in occupied slots (ms)=66149
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=66149
		Total vcore-seconds taken by all map tasks=66149
		Total megabyte-seconds taken by all map tasks=67736576
	Map-Reduce Framework
		Map input records=2
		Map output records=10
		Input split bytes=214
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=877
		CPU time spent (ms)=4620
		Physical memory (bytes) snapshot=202948608
		Virtual memory (bytes) snapshot=1953030144
		Total committed heap usage (bytes)=47710208
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=398
16/06/20 21:08:06 INFO mapreduce.ImportJobBase: Transferred 398 bytes in 76.6371 seconds (5.1933 bytes/sec)
16/06/20 21:08:06 INFO mapreduce.ImportJobBase: Retrieved 10 records.

[hduser@Inceptez ~]$ hdfs dfs -ls -R sqoopdb/Employee_new1
-rw-r--r--   1 hduser supergroup          0 2016-06-20 21:08 sqoopdb/Employee_new1/_SUCCESS
-rw-r--r--   1 hduser supergroup        199 2016-06-20 21:08 sqoopdb/Employee_new1/part-m-00000
-rw-r--r--   1 hduser supergroup        199 2016-06-20 21:08 sqoopdb/Employee_new1/part-m-00001
[hduser@Inceptez ~]$ hdfs dfs -cat sqoopdb/Employee_new1/p*0
1,Deepak,75000.00,2016-06-13 11:36:27
2,Sachin,1500000.00,2016-06-13 11:37:51
3,Messi,2500000.00,2016-06-13 11:38:04
4,Federer,2000000.00,2016-06-13 12:18:19
5,Ronaldo,2750000.00,2016-06-18 02:58:31
[hduser@Inceptez ~]$ hdfs dfs -cat sqoopdb/Employee_new1/p*1
6,Iniesta,1000000.00,2016-06-20 15:17:12
7,Giggs,900000.00,2016-06-20 15:17:43
8,Rooney,2000000.00,2016-06-20 15:18:40
9,Neymar,1750000.00,2016-06-20 15:19:06
10,Dhoni,2100000.00,2016-06-20 15:20:22
====================================================================================================
[hduser@Inceptez ~]$ sqoop import --connect jdbc:mysql://localhost/DKMDB01 --username root --P --direct --query 'select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and $CONDITIONS' --split-by a.Emp_id --target-dir join_query_op2;
Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/local/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
16/06/20 21:14:24 INFO sqoop.Sqoop: Running Sqoop version: 1.4.5
Enter password: 
16/06/20 21:14:28 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/06/20 21:14:28 INFO tool.CodeGenTool: Beginning code generation
16/06/20 21:14:29 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/20 21:14:29 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/20 21:14:29 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/20 21:14:29 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/local/hadoop
Note: /tmp/sqoop-hduser/compile/ad00668e2dedf638eac0fdbc54b2bb7a/QueryResult.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/06/20 21:14:35 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hduser/compile/ad00668e2dedf638eac0fdbc54b2bb7a/QueryResult.jar
16/06/20 21:14:35 INFO mapreduce.ImportJobBase: Beginning query import.
16/06/20 21:14:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/06/20 21:14:36 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
16/06/20 21:14:38 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
16/06/20 21:14:38 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/06/20 21:14:41 INFO db.DBInputFormat: Using read commited transaction isolation
16/06/20 21:14:41 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(t1.Emp_id), MAX(t1.Emp_id) FROM (select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 1) ) AS t1
16/06/20 21:14:41 INFO mapreduce.JobSubmitter: number of splits:4
16/06/20 21:14:42 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1466435175955_0002
16/06/20 21:14:43 INFO impl.YarnClientImpl: Submitted application application_1466435175955_0002
16/06/20 21:14:43 INFO mapreduce.Job: The url to track the job: http://Inceptez:8088/proxy/application_1466435175955_0002/
16/06/20 21:14:43 INFO mapreduce.Job: Running job: job_1466435175955_0002
16/06/20 21:15:04 INFO mapreduce.Job: Job job_1466435175955_0002 running in uber mode : false
16/06/20 21:15:04 INFO mapreduce.Job:  map 0% reduce 0%
16/06/20 21:16:14 INFO mapreduce.Job:  map 75% reduce 0%
16/06/20 21:16:16 INFO mapreduce.Job:  map 100% reduce 0%
16/06/20 21:16:17 INFO mapreduce.Job: Job job_1466435175955_0002 completed successfully
16/06/20 21:16:17 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=459068
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=426
		HDFS: Number of bytes written=255
		HDFS: Number of read operations=16
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Job Counters 
		Launched map tasks=4
		Other local map tasks=4
		Total time spent by all maps in occupied slots (ms)=264835
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=264835
		Total vcore-seconds taken by all map tasks=264835
		Total megabyte-seconds taken by all map tasks=271191040
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Input split bytes=426
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=3844
		CPU time spent (ms)=10400
		Physical memory (bytes) snapshot=402632704
		Virtual memory (bytes) snapshot=3902328832
		Total committed heap usage (bytes)=95420416
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=255
16/06/20 21:16:17 INFO mapreduce.ImportJobBase: Transferred 255 bytes in 99.672 seconds (2.5584 bytes/sec)
16/06/20 21:16:17 INFO mapreduce.ImportJobBase: Retrieved 12 records.

[hduser@Inceptez ~]$ hdfs dfs -ls -R join_query_op2
-rw-r--r--   1 hduser supergroup          0 2016-06-20 21:16 join_query_op2/_SUCCESS
-rw-r--r--   1 hduser supergroup        103 2016-06-20 21:16 join_query_op2/part-m-00000
-rw-r--r--   1 hduser supergroup         63 2016-06-20 21:16 join_query_op2/part-m-00001
-rw-r--r--   1 hduser supergroup         42 2016-06-20 21:16 join_query_op2/part-m-00002
-rw-r--r--   1 hduser supergroup         47 2016-06-20 21:16 join_query_op2/part-m-00003
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op2/p*0
1,Deepak,Manchester United
1,Deepak,Team India
2,Sachin,Team India
3,Messi,Barcelona
3,Messi,Argentina
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op2/p*1
4,Federer,Switzerland
5,Ronaldo,Real Madrid
5,Ronaldo,Portugal
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op2/p*2
6,Iniesta,Spain
7,Giggs,Manchester United
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op2/p*3
10,Dhoni,Team India
8,Rooney,Manchester United

====================================================================================================
[hduser@Inceptez ~]$ sqoop import --connect jdbc:mysql://localhost/DKMDB01 --username root --P --direct --query 'select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and $CONDITIONS' --num-mappers 2 --split-by a.Emp_id --target-dir join_query_op3;
Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/local/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
16/06/20 21:20:47 INFO sqoop.Sqoop: Running Sqoop version: 1.4.5
Enter password: 
16/06/20 21:20:51 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/06/20 21:20:51 INFO tool.CodeGenTool: Beginning code generation
16/06/20 21:20:52 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/20 21:20:52 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/20 21:20:52 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/20 21:20:52 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/local/hadoop
Note: /tmp/sqoop-hduser/compile/471276ae7ab28e4c789d586bf5987e88/QueryResult.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/06/20 21:20:57 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hduser/compile/471276ae7ab28e4c789d586bf5987e88/QueryResult.jar
16/06/20 21:20:58 INFO mapreduce.ImportJobBase: Beginning query import.
16/06/20 21:20:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/06/20 21:20:59 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
16/06/20 21:21:01 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
16/06/20 21:21:01 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/06/20 21:21:05 INFO db.DBInputFormat: Using read commited transaction isolation
16/06/20 21:21:05 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(t1.Emp_id), MAX(t1.Emp_id) FROM (select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 1) ) AS t1
16/06/20 21:21:05 INFO mapreduce.JobSubmitter: number of splits:2
16/06/20 21:21:06 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1466435175955_0003
16/06/20 21:21:07 INFO impl.YarnClientImpl: Submitted application application_1466435175955_0003
16/06/20 21:21:07 INFO mapreduce.Job: The url to track the job: http://Inceptez:8088/proxy/application_1466435175955_0003/
16/06/20 21:21:07 INFO mapreduce.Job: Running job: job_1466435175955_0003
16/06/20 21:21:26 INFO mapreduce.Job: Job job_1466435175955_0003 running in uber mode : false
16/06/20 21:21:26 INFO mapreduce.Job:  map 0% reduce 0%
16/06/20 21:21:55 INFO mapreduce.Job:  map 100% reduce 0%
16/06/20 21:21:56 INFO mapreduce.Job: Job job_1466435175955_0003 completed successfully
16/06/20 21:21:57 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=229534
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=214
		HDFS: Number of bytes written=255
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Job Counters 
		Launched map tasks=2
		Other local map tasks=2
		Total time spent by all maps in occupied slots (ms)=52046
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=52046
		Total vcore-seconds taken by all map tasks=52046
		Total megabyte-seconds taken by all map tasks=53295104
	Map-Reduce Framework
		Map input records=12
		Map output records=12
		Input split bytes=214
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=709
		CPU time spent (ms)=4650
		Physical memory (bytes) snapshot=197185536
		Virtual memory (bytes) snapshot=1950932992
		Total committed heap usage (bytes)=47710208
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=255
16/06/20 21:21:57 INFO mapreduce.ImportJobBase: Transferred 255 bytes in 55.5228 seconds (4.5927 bytes/sec)
16/06/20 21:21:57 INFO mapreduce.ImportJobBase: Retrieved 12 records.

[hduser@Inceptez ~]$ hdfs dfs -ls -R join_query_op3
-rw-r--r--   1 hduser supergroup          0 2016-06-20 21:21 join_query_op3/_SUCCESS
-rw-r--r--   1 hduser supergroup        166 2016-06-20 21:21 join_query_op3/part-m-00000
-rw-r--r--   1 hduser supergroup         89 2016-06-20 21:21 join_query_op3/part-m-00001
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op3/p*0
1,Deepak,Manchester United
1,Deepak,Team India
2,Sachin,Team India
3,Messi,Barcelona
4,Federer,Switzerland
5,Ronaldo,Real Madrid
3,Messi,Argentina
5,Ronaldo,Portugal
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op3/p*1
6,Iniesta,Spain
7,Giggs,Manchester United
10,Dhoni,Team India
8,Rooney,Manchester United

====================================================================================================
[hduser@Inceptez ~]$ sqoop import --connect jdbc:mysql://localhost/DKMDB01 --username root --P --direct --query 'select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and $CONDITIONS' --boundary-query 'select 5, max(a.Emp_id) from Employee a' --split-by a.Emp_id --target-dir join_query_op4;
Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/local/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
16/06/20 21:29:39 INFO sqoop.Sqoop: Running Sqoop version: 1.4.5
Enter password: 
16/06/20 21:29:43 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/06/20 21:29:43 INFO tool.CodeGenTool: Beginning code generation
16/06/20 21:29:43 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/20 21:29:43 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/20 21:29:44 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/20 21:29:44 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/local/hadoop
Note: /tmp/sqoop-hduser/compile/e2f5b789ab37f42f25a11d14b72d63e4/QueryResult.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/06/20 21:29:49 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hduser/compile/e2f5b789ab37f42f25a11d14b72d63e4/QueryResult.jar
16/06/20 21:29:49 INFO mapreduce.ImportJobBase: Beginning query import.
16/06/20 21:29:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/06/20 21:29:50 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
16/06/20 21:29:52 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
16/06/20 21:29:53 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/06/20 21:29:56 INFO db.DBInputFormat: Using read commited transaction isolation
16/06/20 21:29:56 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: select 5, max(a.Emp_id) from Employee a
16/06/20 21:29:56 INFO mapreduce.JobSubmitter: number of splits:4
16/06/20 21:29:57 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1466435175955_0004
16/06/20 21:29:57 INFO impl.YarnClientImpl: Submitted application application_1466435175955_0004
16/06/20 21:29:58 INFO mapreduce.Job: The url to track the job: http://Inceptez:8088/proxy/application_1466435175955_0004/
16/06/20 21:29:58 INFO mapreduce.Job: Running job: job_1466435175955_0004
16/06/20 21:30:16 INFO mapreduce.Job: Job job_1466435175955_0004 running in uber mode : false
16/06/20 21:30:16 INFO mapreduce.Job:  map 0% reduce 0%
16/06/20 21:31:15 INFO mapreduce.Job:  map 50% reduce 0%
16/06/20 21:31:19 INFO mapreduce.Job:  map 75% reduce 0%
16/06/20 21:31:20 INFO mapreduce.Job:  map 100% reduce 0%
16/06/20 21:31:21 INFO mapreduce.Job: Job job_1466435175955_0004 completed successfully
16/06/20 21:31:21 INFO mapreduce.Job: Counters: 31
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=458588
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=426
		HDFS: Number of bytes written=130
		HDFS: Number of read operations=16
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Job Counters 
		Killed map tasks=1
		Launched map tasks=5
		Other local map tasks=5
		Total time spent by all maps in occupied slots (ms)=231601
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=231601
		Total vcore-seconds taken by all map tasks=231601
		Total megabyte-seconds taken by all map tasks=237159424
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Input split bytes=426
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=3315
		CPU time spent (ms)=10100
		Physical memory (bytes) snapshot=407445504
		Virtual memory (bytes) snapshot=3902451712
		Total committed heap usage (bytes)=95420416
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=130
16/06/20 21:31:21 INFO mapreduce.ImportJobBase: Transferred 130 bytes in 88.7363 seconds (1.465 bytes/sec)
16/06/20 21:31:21 INFO mapreduce.ImportJobBase: Retrieved 6 records.

[hduser@Inceptez ~]$ hdfs dfs -ls -R join_query_op4
-rw-r--r--   1 hduser supergroup          0 2016-06-20 21:31 join_query_op4/_SUCCESS
-rw-r--r--   1 hduser supergroup         57 2016-06-20 21:31 join_query_op4/part-m-00000
-rw-r--r--   1 hduser supergroup         26 2016-06-20 21:31 join_query_op4/part-m-00001
-rw-r--r--   1 hduser supergroup         27 2016-06-20 21:31 join_query_op4/part-m-00002
-rw-r--r--   1 hduser supergroup         20 2016-06-20 21:31 join_query_op4/part-m-00003
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op4/p*0
5,Ronaldo,Real Madrid
5,Ronaldo,Portugal
6,Iniesta,Spain
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op4/p*1
7,Giggs,Manchester United
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op4/p*2
8,Rooney,Manchester United
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op4/p*3
10,Dhoni,Team India
====================================================================================================
[hduser@Inceptez ~]$ sqoop import --connect jdbc:mysql://localhost/DKMDB01 --username root --P --direct --query 'select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and $CONDITIONS' --boundary-query 'select 7, max(a.Emp_id) from Employee a' --split-by a.Emp_id --num-mappers 2 --target-dir join_query_op5;
Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/local/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
16/06/20 21:42:32 INFO sqoop.Sqoop: Running Sqoop version: 1.4.5
Enter password: 
16/06/20 21:42:35 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/06/20 21:42:35 INFO tool.CodeGenTool: Beginning code generation
16/06/20 21:42:35 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/20 21:42:35 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/20 21:42:35 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/20 21:42:35 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/local/hadoop
Note: /tmp/sqoop-hduser/compile/3427a27560b32cfac0a5b3e426de9d9a/QueryResult.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/06/20 21:42:38 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hduser/compile/3427a27560b32cfac0a5b3e426de9d9a/QueryResult.jar
16/06/20 21:42:38 INFO mapreduce.ImportJobBase: Beginning query import.
16/06/20 21:42:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/06/20 21:42:38 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
16/06/20 21:42:39 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
16/06/20 21:42:39 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/06/20 21:42:40 INFO db.DBInputFormat: Using read commited transaction isolation
16/06/20 21:42:40 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: select 7, max(a.Emp_id) from Employee a
16/06/20 21:42:41 INFO mapreduce.JobSubmitter: number of splits:2
16/06/20 21:42:41 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1466435175955_0005
16/06/20 21:42:41 INFO impl.YarnClientImpl: Submitted application application_1466435175955_0005
16/06/20 21:42:41 INFO mapreduce.Job: The url to track the job: http://Inceptez:8088/proxy/application_1466435175955_0005/
16/06/20 21:42:41 INFO mapreduce.Job: Running job: job_1466435175955_0005
16/06/20 21:42:51 INFO mapreduce.Job: Job job_1466435175955_0005 running in uber mode : false
16/06/20 21:42:51 INFO mapreduce.Job:  map 0% reduce 0%
16/06/20 21:43:04 INFO mapreduce.Job:  map 100% reduce 0%
16/06/20 21:43:04 INFO mapreduce.Job: Job job_1466435175955_0005 completed successfully
16/06/20 21:43:04 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=229294
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=214
		HDFS: Number of bytes written=73
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Job Counters 
		Launched map tasks=2
		Other local map tasks=2
		Total time spent by all maps in occupied slots (ms)=21439
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=21439
		Total vcore-seconds taken by all map tasks=21439
		Total megabyte-seconds taken by all map tasks=21953536
	Map-Reduce Framework
		Map input records=3
		Map output records=3
		Input split bytes=214
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=253
		CPU time spent (ms)=1880
		Physical memory (bytes) snapshot=201404416
		Virtual memory (bytes) snapshot=1950924800
		Total committed heap usage (bytes)=47710208
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=73
16/06/20 21:43:04 INFO mapreduce.ImportJobBase: Transferred 73 bytes in 25.0387 seconds (2.9155 bytes/sec)
16/06/20 21:43:04 INFO mapreduce.ImportJobBase: Retrieved 3 records.

[hduser@Inceptez ~]$ hdfs dfs -ls -R join_query_op5
-rw-r--r--   1 hduser supergroup          0 2016-06-20 21:43 join_query_op5/_SUCCESS
-rw-r--r--   1 hduser supergroup         53 2016-06-20 21:43 join_query_op5/part-m-00000
-rw-r--r--   1 hduser supergroup         20 2016-06-20 21:43 join_query_op5/part-m-00001
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op5/p*0
7,Giggs,Manchester United
8,Rooney,Manchester United
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op5/p*1
10,Dhoni,Team India
====================================================================================================
mysql> insert into Emp_team values (9,'Bayern Munich',8);
Query OK, 1 row affected (0.00 sec)

mysql> insert into Employee values (6,'Iniesta',1000000,current_timestamp);
Query OK, 1 row affected (0.00 sec)

mysql> insert into Employee values (7,'Giggs',900000,current_timestamp);
Query OK, 1 row affected (0.00 sec)

mysql> insert into Employee values (8,'Rooney',2000000,current_timestamp);
Query OK, 1 row affected (0.00 sec)

mysql> insert into Employee values (9,'Neymar',1750000,current_timestamp);
Query OK, 1 row affected (0.00 sec)

mysql> insert into Employee values (10,'Dhoni',2100000,current_timestamp);
Query OK, 1 row affected (0.00 sec)

mysql> insert into Emp_team values (2,'Team India',10);
Query OK, 1 row affected (0.00 sec)

mysql> insert into Emp_team values (1,'Manchester United',8);
Query OK, 1 row affected (0.00 sec)

mysql> update Emp_team set Emp_id = 11 where Team_id = 9;
Query OK, 1 row affected (0.00 sec)

mysql> select * from Employee;
+--------+----------+------------+---------------------+
| Emp_id | Emp_Name | Emp_sal    | Row_ts              |
+--------+----------+------------+---------------------+
|      1 | Deepak   |   75000.00 | 2016-06-13 17:06:27 |
|      2 | Sachin   | 1500000.00 | 2016-06-13 17:07:51 |
|      3 | Messi    | 2500000.00 | 2016-06-13 17:08:04 |
|      4 | Federer  | 2000000.00 | 2016-06-13 17:48:19 |
|      5 | Ronaldo  | 2750000.00 | 2016-06-18 08:28:31 |
|      6 | Iniesta  | 1000000.00 | 2016-06-20 20:47:12 |
|      7 | Giggs    |  900000.00 | 2016-06-20 20:47:43 |
|      8 | Rooney   | 2000000.00 | 2016-06-20 20:48:40 |
|      9 | Neymar   | 1750000.00 | 2016-06-20 20:49:06 |
|     10 | Dhoni    | 2100000.00 | 2016-06-20 20:50:22 |
+--------+----------+------------+---------------------+
10 rows in set (0.00 sec)

mysql> select * from Emp_team;
+---------+-------------------+--------+
| Team_id | Team_name         | Emp_id |
+---------+-------------------+--------+
|       1 | Manchester United |      1 |
|       2 | Team India        |      1 |
|       2 | Team India        |      2 |
|       3 | Barcelona         |      3 |
|       4 | Switzerland       |      4 |
|       5 | Real Madrid       |      5 |
|       6 | Argentina         |      3 |
|       7 | Portugal          |      5 |
|       8 | Spain             |      6 |
|       1 | Manchester United |      7 |
|       9 | Bayern Munich     |     11 |
|       2 | Team India        |     10 |
|       1 | Manchester United |      8 |
+---------+-------------------+--------+
13 rows in set (0.12 sec)

mysql> delete from Emp_team where Emp_id in (11,10,8);
Query OK, 3 rows affected (0.00 sec)

mysql> select * from Emp_team;
+---------+-------------------+--------+
| Team_id | Team_name         | Emp_id |
+---------+-------------------+--------+
|       1 | Manchester United |      1 |
|       2 | Team India        |      1 |
|       2 | Team India        |      2 |
|       3 | Barcelona         |      3 |
|       4 | Switzerland       |      4 |
|       5 | Real Madrid       |      5 |
|       6 | Argentina         |      3 |
|       7 | Portugal          |      5 |
|       8 | Spain             |      6 |
|       1 | Manchester United |      7 |
+---------+-------------------+--------+
10 rows in set (0.00 sec)

mysql> delete from Employee where Emp_id > 5;
Query OK, 5 rows affected (0.00 sec)

mysql> select * from Employee;
+--------+----------+------------+---------------------+
| Emp_id | Emp_Name | Emp_sal    | Row_ts              |
+--------+----------+------------+---------------------+
|      1 | Deepak   |   75000.00 | 2016-06-13 17:06:27 |
|      2 | Sachin   | 1500000.00 | 2016-06-13 17:07:51 |
|      3 | Messi    | 2500000.00 | 2016-06-13 17:08:04 |
|      4 | Federer  | 2000000.00 | 2016-06-13 17:48:19 |
|      5 | Ronaldo  | 2750000.00 | 2016-06-18 08:28:31 |
+--------+----------+------------+---------------------+
5 rows in set (0.00 sec)
====================================================================================================
[hduser@Inceptez ~]$ sqoop import --connect jdbc:mysql://localhost/DKMDB01 --username root --P --direct --query 'select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and $CONDITIONS' --split-by a.Emp_id --target-dir join_query_op6;
Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/local/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
16/06/21 19:52:16 INFO sqoop.Sqoop: Running Sqoop version: 1.4.5
Enter password: 
16/06/21 19:52:21 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/06/21 19:52:21 INFO tool.CodeGenTool: Beginning code generation
16/06/21 19:52:21 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/21 19:52:21 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/21 19:52:21 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/21 19:52:21 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/local/hadoop
Note: /tmp/sqoop-hduser/compile/743d3b4f06bc56d481b91a99dbf9103d/QueryResult.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/06/21 19:52:26 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hduser/compile/743d3b4f06bc56d481b91a99dbf9103d/QueryResult.jar
16/06/21 19:52:26 INFO mapreduce.ImportJobBase: Beginning query import.
16/06/21 19:52:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/06/21 19:52:27 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
16/06/21 19:52:28 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
16/06/21 19:52:28 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/06/21 19:52:31 INFO db.DBInputFormat: Using read commited transaction isolation
16/06/21 19:52:31 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(t1.Emp_id), MAX(t1.Emp_id) FROM (select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 1) ) AS t1
16/06/21 19:52:31 INFO mapreduce.JobSubmitter: number of splits:5
16/06/21 19:52:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1466518504658_0001
16/06/21 19:52:32 INFO impl.YarnClientImpl: Submitted application application_1466518504658_0001
16/06/21 19:52:33 INFO mapreduce.Job: The url to track the job: http://Inceptez:8088/proxy/application_1466518504658_0001/
16/06/21 19:52:33 INFO mapreduce.Job: Running job: job_1466518504658_0001
16/06/21 19:52:46 INFO mapreduce.Job: Job job_1466518504658_0001 running in uber mode : false
16/06/21 19:52:46 INFO mapreduce.Job:  map 0% reduce 0%
16/06/21 19:53:17 INFO mapreduce.Job:  map 20% reduce 0%
16/06/21 19:53:19 INFO mapreduce.Job:  map 40% reduce 0%
16/06/21 19:53:21 INFO mapreduce.Job:  map 60% reduce 0%
16/06/21 19:53:22 INFO mapreduce.Job:  map 100% reduce 0%
16/06/21 19:53:23 INFO mapreduce.Job: Job job_1466518504658_0001 completed successfully
16/06/21 19:53:23 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=573835
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=531
		HDFS: Number of bytes written=166
		HDFS: Number of read operations=20
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Launched map tasks=5
		Other local map tasks=5
		Total time spent by all maps in occupied slots (ms)=149412
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=149412
		Total vcore-seconds taken by all map tasks=149412
		Total megabyte-seconds taken by all map tasks=152997888
	Map-Reduce Framework
		Map input records=8
		Map output records=8
		Input split bytes=531
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=1474
		CPU time spent (ms)=5650
		Physical memory (bytes) snapshot=489213952
		Virtual memory (bytes) snapshot=4877742080
		Total committed heap usage (bytes)=119275520
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=166
16/06/21 19:53:23 INFO mapreduce.ImportJobBase: Transferred 166 bytes in 54.9471 seconds (3.0211 bytes/sec)
16/06/21 19:53:23 INFO mapreduce.ImportJobBase: Retrieved 8 records.

[hduser@Inceptez ~]$ hdfs dfs -ls -R join_query_op6
-rw-r--r--   1 hduser supergroup          0 2016-06-21 19:53 join_query_op6/_SUCCESS
-rw-r--r--   1 hduser supergroup         47 2016-06-21 19:53 join_query_op6/part-m-00000
-rw-r--r--   1 hduser supergroup         20 2016-06-21 19:53 join_query_op6/part-m-00001
-rw-r--r--   1 hduser supergroup         36 2016-06-21 19:53 join_query_op6/part-m-00002
-rw-r--r--   1 hduser supergroup         22 2016-06-21 19:53 join_query_op6/part-m-00003
-rw-r--r--   1 hduser supergroup         41 2016-06-21 19:53 join_query_op6/part-m-00004
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op6/p*0
1,Deepak,Manchester United
1,Deepak,Team India
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op6/p*1
2,Sachin,Team India
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op6/p*2
3,Messi,Barcelona
3,Messi,Argentina
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op6/p*3
4,Federer,Switzerland
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op6/p*4
5,Ronaldo,Real Madrid
5,Ronaldo,Portugal

====================================================================================================
[hduser@Inceptez ~]$ sqoop import --connect jdbc:mysql://localhost/DKMDB01 --username root --P --direct --query 'select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and $CONDITIONS' --boundary-query 'select 3, max(a.Emp_id) from Employee a' --num-mappers 2 --split-by a.Emp_id --target-dir join_query_op7;
Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/local/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/local/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
16/06/21 19:57:34 INFO sqoop.Sqoop: Running Sqoop version: 1.4.5
Enter password: 
16/06/21 19:57:38 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
16/06/21 19:57:38 INFO tool.CodeGenTool: Beginning code generation
16/06/21 19:57:38 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/21 19:57:38 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/21 19:57:38 INFO manager.SqlManager: Executing SQL statement: select a.Emp_id, a.Emp_name, b.Team_name from Employee a, Emp_team b where a.Emp_id = b.Emp_id and  (1 = 0) 
16/06/21 19:57:38 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/local/hadoop
Note: /tmp/sqoop-hduser/compile/3bf183e0b32b1478d807533f8cdd7e4e/QueryResult.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
16/06/21 19:57:43 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hduser/compile/3bf183e0b32b1478d807533f8cdd7e4e/QueryResult.jar
16/06/21 19:57:43 INFO mapreduce.ImportJobBase: Beginning query import.
16/06/21 19:57:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/06/21 19:57:43 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
16/06/21 19:57:44 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
16/06/21 19:57:44 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/06/21 19:57:47 INFO db.DBInputFormat: Using read commited transaction isolation
16/06/21 19:57:47 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: select 3, max(a.Emp_id) from Employee a
16/06/21 19:57:47 INFO mapreduce.JobSubmitter: number of splits:3
16/06/21 19:57:47 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1466518504658_0002
16/06/21 19:57:48 INFO impl.YarnClientImpl: Submitted application application_1466518504658_0002
16/06/21 19:57:48 INFO mapreduce.Job: The url to track the job: http://Inceptez:8088/proxy/application_1466518504658_0002/
16/06/21 19:57:48 INFO mapreduce.Job: Running job: job_1466518504658_0002
16/06/21 19:57:58 INFO mapreduce.Job: Job job_1466518504658_0002 running in uber mode : false
16/06/21 19:57:58 INFO mapreduce.Job:  map 0% reduce 0%
16/06/21 19:58:16 INFO mapreduce.Job:  map 33% reduce 0%
16/06/21 19:58:17 INFO mapreduce.Job:  map 67% reduce 0%
16/06/21 19:58:18 INFO mapreduce.Job:  map 100% reduce 0%
16/06/21 19:58:18 INFO mapreduce.Job: Job job_1466518504658_0002 completed successfully
16/06/21 19:58:18 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=343941
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=319
		HDFS: Number of bytes written=99
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Job Counters 
		Launched map tasks=3
		Other local map tasks=3
		Total time spent by all maps in occupied slots (ms)=47404
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=47404
		Total vcore-seconds taken by all map tasks=47404
		Total megabyte-seconds taken by all map tasks=48541696
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Input split bytes=319
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=559
		CPU time spent (ms)=3060
		Physical memory (bytes) snapshot=307183616
		Virtual memory (bytes) snapshot=2926387200
		Total committed heap usage (bytes)=71565312
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=99
16/06/21 19:58:18 INFO mapreduce.ImportJobBase: Transferred 99 bytes in 34.2909 seconds (2.8871 bytes/sec)
16/06/21 19:58:18 INFO mapreduce.ImportJobBase: Retrieved 5 records.
[hduser@Inceptez ~]$ hdfs dfs -ls -R join_query_op7
16/06/21 20:01:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
-rw-r--r--   1 hduser supergroup          0 2016-06-21 19:58 join_query_op7/_SUCCESS
-rw-r--r--   1 hduser supergroup         36 2016-06-21 19:58 join_query_op7/part-m-00000
-rw-r--r--   1 hduser supergroup         22 2016-06-21 19:58 join_query_op7/part-m-00001
-rw-r--r--   1 hduser supergroup         41 2016-06-21 19:58 join_query_op7/part-m-00002
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op7/p*0
16/06/21 20:01:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
3,Messi,Barcelona
3,Messi,Argentina
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op7/p*1
16/06/21 20:01:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
^[[A4,Federer,Switzerland
[hduser@Inceptez ~]$ hdfs dfs -cat join_query_op7/p*2
16/06/21 20:01:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
5,Ronaldo,Real Madrid
5,Ronaldo,Portugal

====================================================================================================
